include 'ac_simple_navigation.gin'

CHANNEL_ORDER='channels_last'
FrameStack.channel_order=%CHANNEL_ORDER
FrameStack.field_to_stack='image'  # due to observation including image and sentence

create_environment.num_parallel_environments=30

create_environment.env_name='SocialBot-GroceryGroundImageLanguage-v0'
GroceryGround.resized_image_size=(128, 128)

GroceryGround.image_data_format=%CHANNEL_ORDER
tf.keras.layers.Conv2D.data_format=%CHANNEL_ORDER

ActorDistributionRnnNetwork.continuous_projection_net=@NormalProjectionNetwork
NormalProjectionNetwork.init_means_output_factor=1e-10
NormalProjectionNetwork.std_bias_initializer_value=0.0

ActorDistributionRnnNetwork.activation_fn=@tf.nn.elu
ActorDistributionRnnNetwork.discrete_projection_net=@CategoricalProjectionNetwork
ActorDistributionRnnNetwork.lstm_size=(128, 128)

ValueRnnNetwork.activation_fn=@tf.nn.elu
ValueRnnNetwork.lstm_size=(128, 128)

ac/Adam.learning_rate=2e-4

observation_spec=@get_observation_spec()
action_spec=@get_action_spec()
vocab_size=@get_vocab_size()  # must have sentence as part of observation

#PolicyDriver.use_xla=True

RLAlgorithm.enable_mixed_precision=True
get_dtype.dtype=%tf.float16
suite_socialbot.load.spec_dtype_map = @gym_space_to_float16_mapping()
ActorDistributionRnnNetwork.dtype=%tf.float16
ValueRnnNetwork.dtype=%tf.float16
TrainerConfig.keras_floatx='float16'
# make sure image scale transformer is applied, so input to nets will be in float16

num_embedding_dims=16
fc_layer_params=(256,)
get_conv_layers.conv_layer_params=((16, 3, 2), (32, 3, 2))
conv_layers = @get_conv_layers()
sentence/generate_network.structure=(
    'tf.keras.Sequential',
        [('tf.keras.layers.Embedding', %vocab_size, %num_embedding_dims),
         ('tf.keras.layers.GlobalAveragePooling1D')])
sentence_layers = @sentence/generate_network()

preprocessing_layers={
    'image': %conv_layers,
    'sentence': %sentence_layers}

combiner/generate_network.structure=('tf.keras.layers.Concatenate',)
preprocessing_combiner=@combiner/generate_network()

ActorDistributionRnnNetwork.input_tensor_spec=%observation_spec
ActorDistributionRnnNetwork.output_tensor_spec=%action_spec
ActorDistributionRnnNetwork.preprocessing_layers=%preprocessing_layers
ActorDistributionRnnNetwork.preprocessing_combiner=%preprocessing_combiner
ActorDistributionRnnNetwork.input_fc_layer_params=%fc_layer_params

ValueRnnNetwork.input_tensor_spec=%observation_spec
ValueRnnNetwork.preprocessing_layers=%preprocessing_layers
ValueRnnNetwork.preprocessing_combiner=%preprocessing_combiner
ValueRnnNetwork.input_fc_layer_params=%fc_layer_params

actor=@ActorDistributionRnnNetwork()
value=@ValueRnnNetwork()

ActorCriticAlgorithm.actor_network=%actor
ActorCriticAlgorithm.value_network=%value

Agent.gradient_clipping=0.5


suite_socialbot.load.max_episode_steps=1000
GroceryGroundGoalTask.max_steps=200

GroceryGroundGoalTask.fail_distance_thresh=10
GroceryGroundGoalTask.random_goal=False
#GroceryGroundGoalTask.random_range=2
GroceryGroundGoalTask.goal_name='ball'

#Curriculum
GroceryGroundGoalTask.use_curriculum_training=True
GroceryGroundGoalTask.start_range=1
GroceryGroundGoalTask.max_reward_q_length=100
GroceryGroundGoalTask.reward_thresh_to_increase_range=0.9
GroceryGroundGoalTask.increase_range_by_percent=0.1
GroceryGroundGoalTask.percent_full_range_in_curriculum=0.2

TrainerConfig.checkpoint_interval=100
TrainerConfig.unroll_length=50
TrainerConfig.evaluate=False

TrainerConfig.use_tf_functions=0
