import alf.algorithms.actor_critic_algorithm
import alf.algorithms.agent
import alf.environments.suite_gym
import alf.environments.suite_socialbot

create_environment.num_parallel_environments=30

create_environment.env_name='SocialBot-PlayGround-v0'
create_environment.env_load_fn=@suite_socialbot.load
PlayGround.use_image_observation=False
PlayGround.with_language=False
PlayGround.resized_image_size=(84, 84)

GoalTask.polar_coord=False

# suite_socialbot.load.gym_env_wrappers=(@FrameStack,)
# FrameStack.fields=['image']  # must be a subset of input observations
# image_scale_transformer.fields=['image']
# alf.environments.gym_wrappers.ImageChannelFirst.fields=['image']
suite_gym.wrap_env.image_channel_first=False

import alf.algorithms.trac_algorithm

Agent.rl_algorithm_cls=@TracAlgorithm
Agent.observation_transformer=@image_scale_transformer
Agent.optimizer=@ac/AdamTF()
ac/AdamTF.lr=1e-4
ac/AdamTF.gradient_clipping=0.5

TracAlgorithm.ac_algorithm_cls=@ActorCriticAlgorithm
TracAlgorithm.action_dist_clip_per_dim=0.01

ActorDistributionRNNNetwork.lstm_hidden_size=(128, 128)
ActorDistributionRNNNetwork.activation=@torch.nn.functional.elu_

ValueRNNNetwork.lstm_hidden_size=(128, 128)
ValueRNNNetwork.activation=@torch.nn.functional.elu_

ActorDistributionNetwork.activation=@torch.nn.functional.elu_
ValueNetwork.activation=@torch.nn.functional.elu_

conv_layer_params=((16, 3, 2), (32, 3, 2))
num_embedding_dims=16
fc_layer_params=(256,)

import alf.networks.target_navigation

target_navigation.get_actor_network.conv_layer_params=%conv_layer_params
target_navigation.get_actor_network.num_embedding_dims=%num_embedding_dims
target_navigation.get_actor_network.fc_layer_params=%fc_layer_params

target_navigation.get_value_network.conv_layer_params=%conv_layer_params
target_navigation.get_value_network.num_embedding_dims=%num_embedding_dims
target_navigation.get_value_network.fc_layer_params=%fc_layer_params

ActorCriticAlgorithm.actor_network=@target_navigation.get_actor_network()
ActorCriticAlgorithm.value_network=@target_navigation.get_value_network()

ActorCriticLoss.use_gae=True
ActorCriticLoss.use_td_lambda_return=True
ActorCriticLoss.entropy_regularization=0.0005

suite_socialbot.load.max_episode_steps=1000
GoalTask.max_steps=100
PlayGround.max_steps=100

GoalTask.fail_distance_thresh=1000
GoalTask.random_goal=False
#GoalTask.random_range=5
GoalTask.goal_name='ball'

#Curriculum
GoalTask.use_curriculum_training=True
GoalTask.start_range=1
GoalTask.max_reward_q_length=100
GoalTask.reward_thresh_to_increase_range=0.9
GoalTask.increase_range_by_percent=0.1
GoalTask.percent_full_range_in_curriculum=0.2

# training config
TrainerConfig.unroll_length=100
TrainerConfig.algorithm_ctor=@Agent
TrainerConfig.num_iterations=100000
TrainerConfig.num_checkpoints=1000  # checkpoint every 100 iterations
TrainerConfig.debug_summaries=True
TrainerConfig.summarize_grads_and_vars=1
TrainerConfig.summary_interval=1
