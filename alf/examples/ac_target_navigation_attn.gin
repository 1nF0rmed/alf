include 'ac_target_navigation.gin'

target_navigation.get_ac_networks.attention=True

PlayGround.group_img_lang=True

FrameStack.fields_to_stack=['image_sentence.image']  # must be a subset of input observations
image_scale_transformer.fields=['image_sentence.image']

num_state_tiles=0
num_sentence_tiles=0
# number of filters in first conv2d layer has to be 12 to match
# input number of channels 3 (channels/frame) x 4 (frames).
# Otherwise, expect to see ValueError: number of input channels does not match corresponding dimension of filter.
# But Why?
conv_layer_params=((12, 3, 2), (32, 3, 2))

import alf.networks.target_navigation
target_navigation.get_actor_network.conv_layer_params=%conv_layer_params
target_navigation.get_actor_network.num_state_tiles=%num_state_tiles
target_navigation.get_actor_network.num_sentence_tiles=%num_sentence_tiles

target_navigation.get_value_network.conv_layer_params=%conv_layer_params
target_navigation.get_value_network.num_state_tiles=%num_state_tiles
target_navigation.get_value_network.num_sentence_tiles=%num_sentence_tiles

TrainerConfig.use_tf_functions=1
